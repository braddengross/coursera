evergage_data_for_sf_accounts$totalActions <- lapply(evergage_data_for_sf_accounts$totalActions, as.numeric)
evergage_data_for_sf_accounts$name <- unlist(evergage_data_for_sf_accounts$name)
evergage_data_for_sf_accounts$totalActions <- unlist(evergage_data_for_sf_accounts$totalActions)
query_result <- query_result[query_result$Name %in% evergage_data_for_sf_accounts$name,]
View(evergage_data_for_sf_accounts)
View(query_result)
query_result$Name <- as.character(query_result$Name)
query_result <-query_result[order(query_result$Name), ]
View(evergage_data_for_sf_accounts)
View(query_result)
data <- data.frame(evergage_data_for_sf_accounts$name, evergage_data_for_sf_accounts$totalActions, query_result$Name,
query_result$last_login__c, query_result$num_saved_report__c,
query_result$num_scheduled_policies__c, query_result$num_scheduled_report__c)
colnames(data) <- c("E - Name", "E - Total Actions", "S - Name", "S - Last Login", "S - Saved Report Count", "S - Scheduled Policy Count", "S - Scheduled Report Count")
View(data)
day.start <- "2012/10/01"
day.end <- "2013/01/07"
dayseq <- seq.Date(as.Date(day.start),as.Date(day.end),by="week")
weeks = length(dayseq)
time_analysis_sample_data <- data.frame(
dayseq,
domain = rep("test.cloud8labs", weeks),
version = c(rep("Trial", weeks / 3), rep("Basic", weeks / 3), rep("Enterprise", weeks / 3)),
edu_non_prof = c(rep(FALSE, 15)),
reports_count = c(0, rep(1, 3), rep(3, 8), rep(5, 3)),
man_syncs_run = c(3, 2, 2, 3, 4, rep(0, 5), rep(2, 5)),
drive_policies_conut = c(rep(0, 2), rep(1, 8), rep(2, 5))
)
View(time_analysis_sample_data)
find_trial_end <- fucntion(time_analysis_sample_data) {
weeks_as_trial <- time_analysis_sample_data[time_analysis_sample_data$version == "Trial", ]
weeks_as_trial <- weeks_as_trial[order(weeks_as_trial$dayseq),]
trial_end_week <- weeks_as_trial[nrow(weeks_as_trial),]
trial_end_week
}
find_conversion_point <- function(time_analysis_sample_data){
weeks_as_enterprise <- time_analysis_sample_data[time_analysis_sample_data$version == "Enterprise", ]
weeks_as_enterprise <- weeks_as_enterprise[order(weeks_as_enterprise$dayseq),]
conversion_week <- weeks_as_enterprise[1,]
conversion_week
}
data_leading_to_conversion <- function(time_analysis_sample_data, weeks = 4) {
conv_date <- find_conversion_point(time_analysis_sample_data)
dates <- seq.Date(from = conv_date$dayseq, by = "-1 week", length.out = weeks)
data_leading_up_to_conversion <- time_analysis_sample_data[time_analysis_sample_data$dayseq %in% dates,]
data_leading_up_to_conversion
}
find_trial_end <- fucntion(time_analysis_sample_data) {
weeks_as_trial <- time_analysis_sample_data[time_analysis_sample_data$version == "Trial", ]
weeks_as_trial <- weeks_as_trial[order(weeks_as_trial$dayseq),]
trial_end_week <- weeks_as_trial[nrow(weeks_as_trial),]
trial_end_week
}
find_trial_end <- function(time_analysis_sample_data) {
weeks_as_trial <- time_analysis_sample_data[time_analysis_sample_data$version == "Trial", ]
weeks_as_trial <- weeks_as_trial[order(weeks_as_trial$dayseq),]
trial_end_week <- weeks_as_trial[nrow(weeks_as_trial),]
trial_end_week
}
library(httr)
install.packages("RForcecom", dependencies = TRUE)
library(jsonlite)
library("RForcecom")
options(stringsAsFactors = FALSE)
install.packages("RForcecom", dependencies = TRUE)
accounts_json_resp <- GET("https://bettercloud.evergage.com/api/dataset/engage/accounts.json?_at=C2C0FC23-4A2A-9D7D-A831-E4B10644399D")
account_json_content <- content(accounts_json_resp)
account_json <- jsonlite::fromJSON(toJSON(account_json_content))
library(xml)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
cited_by <- xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
cited_by
html
cited_by <- xpathSApply(html, "//td[@id='gsc_a_c']", xmlValue)
cited_by <- xpathSApply(html, "//td[@id='gsc_a_c']", xmlValue)
cited_by
xpathSApply(html, "//td[@id='gsc_a_c']", xmlValue)
library(httr)
html2 <= GET(url)
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText = TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("uesr","password"))
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("user","password"))
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("user","passwd"))
pg1
names(pg1)
#Using handles
google = handle("http://google.com")
pg1 = GET(handle=google, path="/")
pg1
pg2 = GET(handle=google, path="search")
pg2
library(httr)
oauth_endpoints("github")
oauth_endpoints("github")
?oauth_app
myapp <- oauth_app("github", "f4a0559a529d341e8964", "6cabb8b2ea01d6d0659266adbea7baab157070d9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
reqContent <- content(req)
reqContent <- content(req, as="text")
parsedHtml <- htmlParse(reqContent, asText = TRUE)
xpathSApply(parsedHtml, "//name", xmlValue)
xpathSApply(parsedHtml, "//$name", xmlValue)
xpathSApply(parsedHtml, "//name", xmlValue)
xpathSApply(parsedHtml, "//name", jsonValue)
xpathSApply(parsedHtml, "//name", value)
rootNode <- xmlRoot(reqContent)
rootNode <- xmlRoot(parsedHtml)
rootNode
v
names(rootNode)
names(parsedHtml)
parsedHtml <- htmlParse(reqContent, asText = TRUE)
xpathSApply(parsedHtml, xmlValue)
xpathSApply(parsedHtml, "//", xmlValue)
parsedHtml
xpathSApply(parsedHtml, "//name", xmlValue)
names <- xpathSApply(parsedHtml, "//name", xmlValue)
install.packages("RMySQL")
require("RMySQL")
?dbConnect
asc <- dbConnect(MySQL(), host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
install.packages("sqldf")
require("sqldf")
?read.csv
asc <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
names(asc)
asc <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
?download.file
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destFile="acs.csv",method="curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile="acs.csv",method="curl")
asc <- read.csv("asc.csv")
asc <- read.csv("acs.csv")
names(asc)
sqldf("select pwgtp1 from acs where AGEP < 50")
read.csv.sql("asc.csv", "select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1 from asc where AGEP < 50")
class(asc)
sqldf("select * from asc")
install.packages("sqldf")
options(sqldf.driver = "SQLite") # as per FAQ #7 force SQLite
options(gsubfn.engine = "R") # as per FAQ #5 use R code rather than tcltk
library(RMySQL)
library(sqldf)
sqldf("select * from asc")
sqldf("select pwgtp1 from asc where AGEP < 50")
sqldf("select distinct AGEP from acs")
sqldf("select distinct AGEP from asc")
sqldf("select unique AGEP from asc")
#Question 3 (cont'd from question 2)
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html "
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText = TRUE)
pasedHtml
parsedHtml
class(parsedHtml)
line10 <- parsedHtml[10]
line10 <- parsedHtml[10,0]
library(XML)
htmlTable <- readHTMLTable(parsedHtml)
htmlTable
parsedHtml
url <- "http://biostat.jhsph.edu/~jleek/contact.html "
con = url(url)
htmlCode = readLines(con)
close(con)
htmlCode
line10 <- htmlCode[10]
line10 <- nchar(htmlCode[10])
line10 <- nchar(htmlCode[10])
line20 <- nchar(htmlCode[20])
line30 <- nchar(htmlCode[30])
line100 <- nchar(htmlCode[100])
?read.fwf
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "fwf.for")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "fwf.for")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "fwf.for", method ="curl")
data <- read.fwf("fwf.for", widths = 1)
data
data <- read.fwf("fwf.for", widths = 2)
data
data <- read.fwf("fwf.for", widths = 29)
data <- read.fwf("fwf.for", widths = 9)
data
data <- read.fwf("fwf.for", widths = 1000)
data
data <- read.fwf(
data <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
class(data)
sum(data$V4)
sum(data$V9)
sum(data$V4) + sum(data$V9)
View(data)
sum(data$V4)
sum(data$V3)
sum(data$V5)
data <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(14, 4,9, 4,9, 4,9, 4,9))
head(1, data)
head(data, 1)
sum(data$V4)
setwd("~/Workspace/Coursera/Cleaning_Data/week_3")
if(!file.exists("./data")){
dir.create("./data")
}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/restaurants.csv", method="curl")
restData <- read.csv("./data/restaurants.csv")
restData <- read.csv("./data/restaurants.csv")
s1 <- seq(1,10,by=2)
s1
if(!file.exists("./data")){
dir.create("./data")
}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile = "./data/restaurants.csv", method="curl")
restData <- read.csv("./data/restaurants.csv")
s1 <- seq(1,10,by=2)
s1
s2 <- seq(1,10,length=3)
s2
x <- c(1,3,8,25,100)
seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong <- ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong, restData$zipCode < 0)
restData$zipGroups <- cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups, restData$zipCode)
library(Hmisc)
install(Hmisc)
library.install(Hmisc)
require("Hsmic")
library("Hmisc")
library("Hmisc")
install.packages("Hmisc")
library("Hmisc")
restData$zipGroups <- cut2(restData$zipCode, g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
yesno <- sample(c("yes", "no"), size=10, replace=TRUE)
yesnofact = factor(yesno, levels=c("yes", no))
yesnofact = factor(yesno, levels=c("yes", "no"))
yes
yesnofact
relevel(yesnofac, ref="yes")
relevel(yesnofact, ref="yes")
yesnofact
as.numeric(yesnofact)
library(plyr)
restData2 <- mutate(restData, zipGroups=cut2(zipCode, g4))
restData2 <- mutate(restData, zipGroups=cut2(zipCode, g=4))
table(restData2$zipGroups)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname", "gear", "cyl"), measure.vars = c("mpg", "hp"))
head(carMelt, n=3)
cylData <- dcast(carMelt, cyl ~ variable)
cylDate
cylData
cylData <- dcast(caarMelt, cyl ~ variable, mean)
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
head(InsectSprays)
tapply(InsectSprays$count, InsectSprays$spray, sum)
spIns = split(InsectSprays$count, InsectSprays$spray)
spins
spIns
sprCount = lapply(spIns, sum)
sprCount
#Combine = back to vector
unlist(sprCount)
sapply(spIns, sum)
ddply(InsectSprays, .(spray), summarize, sum=sum(count))
spraySums <- ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum))
dim(spraySums)
head(spraySums)
library(dplyr)
install.packages(dplyr)
install.packages("dplyr")
library(dplyr)
chicago <- readRDS("chicago.rds")
chicago <- readRDS("chicago.rds")
dim(chicago)
str(chic)
str(chicago)
names(chicago)
head(select(chicago, city:dptp))
head(select(chicago, -(city:dptp))
head(select(chicago, -(city:dptp)))
head(select(chicago, -(city:dptp)))
i <- match("city", names(chicago))
j <- match("dptp", names(chicago))
head(chicago)
head(chicago[, -(i:j)])
chic.f <- filter(chicago, pm25tmean2 > 30)
head(chic.f)
chic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chic.f)
chicago <- arrange(chicago, date)
head(chicago)
tail(chicago)
chicago <- arrange(chicago, desc(date)
)
chicago <- rename(chicago, pm25 = pm25tmean2, dewpoint = dptp)
head(chicago)
#Mutate
chiacgo <- mutate(chicago, pm25detrend = pm25-mean(pm25, na.rm = TRUE))
head(select(chiacgo, pm25, pm25detrend))
#Group by
chicago <- mutate(chicago, tempcat = factor(1 * (tmpd > 80), labels = c("cold", "hot")))
hotcold <- group_by(chicago, tempcat)
hotcold
summarise(hotcold, pm25 = mean(pm25), 03 = max(o3tmean2), no2 = median(no2tmean2))
summarise(hotcold, pm25 = mean(pm25), o3 = max(o3tmean2), no2 = median(no2tmean2))
summarise(hotcold, pm25 = mean(pm25, na.rm = TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2))
if(!file.exists("./data")){dir.create("./data")}
fileUrl1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
download.file(fileUrl2,destfile="./data/solutions.csv",method="curl")
reviews = read.csv("./data/reviews.csv"); solutions <- read.csv("./data/solutions.csv")
head(reviews,2)
mergeData <- merge(reviews, solutions, by.x="solution_id", by.y="id", all= TRUE)
head(mergeData)
interesect(names(solutions), names(reviews))
intersect(names(solutions), names(reviews))
mergedData2 = merge(reviews, solutions, all=TRUE)
head(mergedData2)
df1 = data.frame(id=sample(1:10), x=rnorm(10))
df2 = data.frame(id=sample(1:10), x=rnorm(10))
arrange(join(df1,df2),id)
df2 = data.frame(id=sample(1:10), y=rnorm(10))
arrange(join(df1,df2),id)
df1 = data.frame(id=sample(1:10),x=rnorm(10))
df2 = data.frame(id=sample(1:10),y=rnorm(10))
df3 = data.frame(id=sample(1:10),z=rnorm(10))
dfList = list(df1,df2,df3)
join_all(dfList)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile = "comm.csv", method="curl")
commData <- read.csv("comm.csv")
head(commData)
agricultureLogical <- commData[commData$ACR == 3]
agricultureLogical <- commData[commData$ACR == 3,]
commData <- read.csv("comm.csv")
agricultureLogical <- commData[commData$ACR == 3,]
agricultureLogical <- agricultureLogical[agricultureLogical$AGS == 6]
agricultureLogical <- agricultureLogical[agricultureLogical$AGS == 6,]
head(agricultureLogical)
View(agricultureLogical)
agricultureLogical <- commData[commData$ACR == 3,]
View(agricultureLogical)
agricultureLogical <- commData[(commData$ACR == 3 & commData$AGS == 6,]
agricultureLogical <- commData[(commData$ACR == 3 & commData$AGS == 6),]
head(agricultureLogical)
agricultureLogical <- commData[which(commData$ACR == 3 & commData$AGS == 6),]
head(agricultureLogical)
library(jpeg)
install.packages("jpeg")
library(jpeg)
?jpeg
img <- jpeg("getdata-jeff.jpg")
?quantile
quantile(img, native = true)
img <- readJPEG("getdata-jeff.jpg", native=TRUE)
quantile(img)
?quantile
quantile(img, probs(c(.3,.8)))
quantile(img, probs = c(.3,.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="gdp.csv", method="curl")
csvData <- read.csv("gdp.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="edu.csv", method="curl")
csvData <- read.csv("edu.csv")
gdpData <- read.csv("gdp.csv")
eduData <- read.csv("edu.csv")
head(eduData)
names(gdpData)
head(gdpData)
View(gdpData)
View(eduData)
View(gdpData)
View(eduData)
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode", all= TRUE)
View(gdpEdu)
?merge
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode", all= FALSE)
View(gdpEdu)
View(gdpEdu)
arrange(gdpEdu, desc(Gross.domestic.product.2012))
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
class(gdpEdu$Gross.domestic.product.2012)
gdpEdu$Gross.domestic.product.2012 <- as.numeric(gdpEdu$Gross.domestic.product.2012)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
?arrange
View(gdpData)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="gdp.csv", method="curl")
gdpData <- read.csv("gdp.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="edu.csv", method="curl")
eduData <- read.csv("edu.csv")
View(gdpData)
View(gdpEdu)
View(eduData)
?merge
View(gdpData)
gdpData$X
eduData$CountryCode
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
View(gdpEdu)
View(gdpData)
View(gdpEdu)
View(gdpData)
View(gdpData)
View(eduData)
View(eduData)
highIncomeOECD <- mean(gdpEdu$Gross.domestic.product.2012[gdpEdu$Income.Group == "High income: OECD"])
?mean
highIncomeOECD <- mean(gdpEdu$Gross.domestic.product.2012[gdpEdu$Income.Group == "High income: OECD"], na.rm = TRUE)
gdpEdu$Income.Group <- as.numeric(gdpEdu$Income.Group)
highIncomeOECD <- mean(gdpEdu$Gross.domestic.product.2012[gdpEdu$Income.Group == "High income: OECD"], na.rm = TRUE)
gdpEdu$Income.Group <- character(gdpEdu$Income.Group)
highIncomeOECD <- mean(gdpEdu$Gross.domestic.product.2012[gdpEdu$Income.Group == "High income: OECD",], na.rm = TRUE)
highIncomeOECD <- gdpEdu$Gross.domestic.product.2012[gdpEdu$Income.Group == "High income: OECD",]
highIncomeOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: OECD"),]
View(gdpEdu)
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
highIncomeOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: OECD"),]
View(highIncomeOECD)
mean(highIncomeOECD)
highIncomeOECD <- gdpEdu$Gross.domestic.product.2012
highIncomeOECD <- as.numeric(highIncomeOECD)
mean(highIncomeOECD)
View(gdpData)
View(eduData)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="gdp.csv", method="curl")
gdpData <- read.csv("gdp.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="edu.csv", method="curl")
eduData <- read.csv("edu.csv")
?merge
View(gdpData)
eduDate <- eduData[!is.na(eduData$CountryCode)]
eduDate <- eduData[!is.na(eduData$CountryCode),]
View(eduDate)
gdpData <- gdpData[!is.na(gdpData$X),]
View(gdpData)
View(gdpData)
gdpData$X[1]
gdpData$X[1]
gdpData$X[[1]]
gdpData$X
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
View(gdpData)
?rad.csv
?read.csv
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"))
View(gdpData)
gdpData <- gdpData[!is.na(gdpData$X),]
gdpData <- gdpData[!is.na(gdpData$Gross.domestic.product.2012),]
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
gdpEdu$Gross.domestic.product.2012 <- as.numeric(gdpEdu$Gross.domestic.product.2012)
gdpEdu$Income.Group <- character(gdpEdu$Income.Group)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
highIncomeOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: OECD"),]
highIncomeOECD <- gdpEdu$Gross.domestic.product.2012
highIncomeOECD <- as.numeric(highIncomeOECD)
mean(highIncomeOECD)
highIncomeOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: OECD"),]
highIncomeOECD <- highIncomeOECD$Gross.domestic.product.2012
highIncomeOECD <- as.numeric(highIncomeOECD)
mean(highIncomeOECD)
View(gdpEdu)
highIncomeNonOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: nonOECD"),]
highIncomeNonOECD <- highIncomeNonOECD$Gross.domestic.product.2012
highIncomeNonOECD <- as.numeric(highIncomeNonOECD)
mean(highIncomeOECD)
