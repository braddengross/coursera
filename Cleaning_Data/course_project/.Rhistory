View(evergage_data_for_sf_accounts)
View(query_result)
query_result$Name <- as.character(query_result$Name)
query_result <-query_result[order(query_result$Name), ]
View(evergage_data_for_sf_accounts)
View(query_result)
data <- data.frame(evergage_data_for_sf_accounts$name, evergage_data_for_sf_accounts$totalActions, query_result$Name,
query_result$last_login__c, query_result$num_saved_report__c,
query_result$num_scheduled_policies__c, query_result$num_scheduled_report__c)
colnames(data) <- c("E - Name", "E - Total Actions", "S - Name", "S - Last Login", "S - Saved Report Count", "S - Scheduled Policy Count", "S - Scheduled Report Count")
View(data)
day.start <- "2012/10/01"
day.end <- "2013/01/07"
dayseq <- seq.Date(as.Date(day.start),as.Date(day.end),by="week")
weeks = length(dayseq)
time_analysis_sample_data <- data.frame(
dayseq,
domain = rep("test.cloud8labs", weeks),
version = c(rep("Trial", weeks / 3), rep("Basic", weeks / 3), rep("Enterprise", weeks / 3)),
edu_non_prof = c(rep(FALSE, 15)),
reports_count = c(0, rep(1, 3), rep(3, 8), rep(5, 3)),
man_syncs_run = c(3, 2, 2, 3, 4, rep(0, 5), rep(2, 5)),
drive_policies_conut = c(rep(0, 2), rep(1, 8), rep(2, 5))
)
View(time_analysis_sample_data)
find_trial_end <- fucntion(time_analysis_sample_data) {
weeks_as_trial <- time_analysis_sample_data[time_analysis_sample_data$version == "Trial", ]
weeks_as_trial <- weeks_as_trial[order(weeks_as_trial$dayseq),]
trial_end_week <- weeks_as_trial[nrow(weeks_as_trial),]
trial_end_week
}
find_conversion_point <- function(time_analysis_sample_data){
weeks_as_enterprise <- time_analysis_sample_data[time_analysis_sample_data$version == "Enterprise", ]
weeks_as_enterprise <- weeks_as_enterprise[order(weeks_as_enterprise$dayseq),]
conversion_week <- weeks_as_enterprise[1,]
conversion_week
}
data_leading_to_conversion <- function(time_analysis_sample_data, weeks = 4) {
conv_date <- find_conversion_point(time_analysis_sample_data)
dates <- seq.Date(from = conv_date$dayseq, by = "-1 week", length.out = weeks)
data_leading_up_to_conversion <- time_analysis_sample_data[time_analysis_sample_data$dayseq %in% dates,]
data_leading_up_to_conversion
}
find_trial_end <- fucntion(time_analysis_sample_data) {
weeks_as_trial <- time_analysis_sample_data[time_analysis_sample_data$version == "Trial", ]
weeks_as_trial <- weeks_as_trial[order(weeks_as_trial$dayseq),]
trial_end_week <- weeks_as_trial[nrow(weeks_as_trial),]
trial_end_week
}
find_trial_end <- function(time_analysis_sample_data) {
weeks_as_trial <- time_analysis_sample_data[time_analysis_sample_data$version == "Trial", ]
weeks_as_trial <- weeks_as_trial[order(weeks_as_trial$dayseq),]
trial_end_week <- weeks_as_trial[nrow(weeks_as_trial),]
trial_end_week
}
library(httr)
install.packages("RForcecom", dependencies = TRUE)
library(jsonlite)
library("RForcecom")
options(stringsAsFactors = FALSE)
install.packages("RForcecom", dependencies = TRUE)
accounts_json_resp <- GET("https://bettercloud.evergage.com/api/dataset/engage/accounts.json?_at=C2C0FC23-4A2A-9D7D-A831-E4B10644399D")
account_json_content <- content(accounts_json_resp)
account_json <- jsonlite::fromJSON(toJSON(account_json_content))
library(xml)
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes = TRUE)
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
cited_by <- xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
cited_by
html
cited_by <- xpathSApply(html, "//td[@id='gsc_a_c']", xmlValue)
cited_by <- xpathSApply(html, "//td[@id='gsc_a_c']", xmlValue)
cited_by
xpathSApply(html, "//td[@id='gsc_a_c']", xmlValue)
library(httr)
html2 <= GET(url)
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText = TRUE)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("uesr","password"))
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("user","password"))
pg1
pg1 = GET("http://httpbin.org/basic-auth/user/passwd",
authenticate("user","passwd"))
pg1
names(pg1)
#Using handles
google = handle("http://google.com")
pg1 = GET(handle=google, path="/")
pg1
pg2 = GET(handle=google, path="search")
pg2
library(httr)
oauth_endpoints("github")
oauth_endpoints("github")
?oauth_app
myapp <- oauth_app("github", "f4a0559a529d341e8964", "6cabb8b2ea01d6d0659266adbea7baab157070d9")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
reqContent <- content(req)
reqContent <- content(req, as="text")
parsedHtml <- htmlParse(reqContent, asText = TRUE)
xpathSApply(parsedHtml, "//name", xmlValue)
xpathSApply(parsedHtml, "//$name", xmlValue)
xpathSApply(parsedHtml, "//name", xmlValue)
xpathSApply(parsedHtml, "//name", jsonValue)
xpathSApply(parsedHtml, "//name", value)
rootNode <- xmlRoot(reqContent)
rootNode <- xmlRoot(parsedHtml)
rootNode
v
names(rootNode)
names(parsedHtml)
parsedHtml <- htmlParse(reqContent, asText = TRUE)
xpathSApply(parsedHtml, xmlValue)
xpathSApply(parsedHtml, "//", xmlValue)
parsedHtml
xpathSApply(parsedHtml, "//name", xmlValue)
names <- xpathSApply(parsedHtml, "//name", xmlValue)
install.packages("RMySQL")
require("RMySQL")
?dbConnect
asc <- dbConnect(MySQL(), host="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
install.packages("sqldf")
require("sqldf")
?read.csv
asc <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
names(asc)
asc <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
?download.file
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destFile="acs.csv",method="curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile="acs.csv",method="curl")
asc <- read.csv("asc.csv")
asc <- read.csv("acs.csv")
names(asc)
sqldf("select pwgtp1 from acs where AGEP < 50")
read.csv.sql("asc.csv", "select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1 from asc where AGEP < 50")
class(asc)
sqldf("select * from asc")
install.packages("sqldf")
options(sqldf.driver = "SQLite") # as per FAQ #7 force SQLite
options(gsubfn.engine = "R") # as per FAQ #5 use R code rather than tcltk
library(RMySQL)
library(sqldf)
sqldf("select * from asc")
sqldf("select pwgtp1 from asc where AGEP < 50")
sqldf("select distinct AGEP from acs")
sqldf("select distinct AGEP from asc")
sqldf("select unique AGEP from asc")
#Question 3 (cont'd from question 2)
library(httr)
url <- "http://biostat.jhsph.edu/~jleek/contact.html "
html2 <- GET(url)
content2 <- content(html2, as="text")
parsedHtml <- htmlParse(content2, asText = TRUE)
pasedHtml
parsedHtml
class(parsedHtml)
line10 <- parsedHtml[10]
line10 <- parsedHtml[10,0]
library(XML)
htmlTable <- readHTMLTable(parsedHtml)
htmlTable
parsedHtml
url <- "http://biostat.jhsph.edu/~jleek/contact.html "
con = url(url)
htmlCode = readLines(con)
close(con)
htmlCode
line10 <- htmlCode[10]
line10 <- nchar(htmlCode[10])
line10 <- nchar(htmlCode[10])
line20 <- nchar(htmlCode[20])
line30 <- nchar(htmlCode[30])
line100 <- nchar(htmlCode[100])
?read.fwf
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "fwf.for")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "fwf.for")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "fwf.for", method ="curl")
data <- read.fwf("fwf.for", widths = 1)
data
data <- read.fwf("fwf.for", widths = 2)
data
data <- read.fwf("fwf.for", widths = 29)
data <- read.fwf("fwf.for", widths = 9)
data
data <- read.fwf("fwf.for", widths = 1000)
data
data <- read.fwf(
data <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
class(data)
sum(data$V4)
sum(data$V9)
sum(data$V4) + sum(data$V9)
View(data)
sum(data$V4)
sum(data$V3)
sum(data$V5)
data <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(14, 4,9, 4,9, 4,9, 4,9))
head(1, data)
head(data, 1)
sum(data$V4)
install.packages("jpeg")
library(jpeg)
img <- readJPEG("getdata-jeff.jpg", native=TRUE)
quantile(img, probs = c(.3,.8))
setwd("~/Workspace/Coursera/Cleaning_Data/week_3")
img <- readJPEG("getdata-jeff.jpg", native=TRUE)
quantile(img, probs = c(.3,.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", destfile="gdp.csv", method="curl")
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"))
gdpData <- gdpData[!is.na(gdpData$X),]
gdpData <- gdpData[!is.na(gdpData$Gross.domestic.product.2012),]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="edu.csv", method="curl")
eduData <- read.csv("edu.csv")
eduData <- eduData[!is.na(eduData$CountryCode),]
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
View(gdpEdu)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
??arange
install.packages("dplyr")
library(dplyr)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
gdpEdu$Gross.domestic.product.2012 <- as.numeric(gdpEdu$Gross.domestic.product.2012)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
gdpEdu$Gross.domestic.product.2012 <- as.numeric(gdpEdu$Gross.domestic.product.2012)
gdpEdu <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEdu)
View(gdpData)
View(gdpEdu)
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
View(gdpEdu)
?arrange
View(gdpEdu)
gdpEduArranged <- arrange(gdpEdu, Gross.domestic.product.2012)
View(gdpEduArranged)
gdpData$Gross.domestic.product.2012 <- as.numeric(gdpData$Gross.domestic.product.2012)
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
gdpEduArranged <- arrange(gdpEdu, Gross.domestic.product.2012)
View(gdpEduArranged)
View(gdpEdu)
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"))
gdpData <- gdpData[!is.na(gdpData$X),]
gdpData <- gdpData[!is.na(gdpData$Gross.domestic.product.2012),]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", destfile="edu.csv", method="curl")
eduData <- read.csv("edu.csv")
eduData <- eduData[!is.na(eduData$CountryCode),]
View(gdpData)
gdpData$Gross.domestic.product.2012 <- as.numeric(gdpData$Gross.domestic.product.2012)
View(gdpData)
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"))
gdpData <- gdpData[!is.na(gdpData$X),]
gdpData <- gdpData[!is.na(gdpData$Gross.domestic.product.2012),]
View(gdpData)
View(gdpData)
?read.csv
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"), colClasses = c("character", "numeric", rep("character",8))
)
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"), colClasses = c("character", "character", "numeric", rep("character",8)))
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"), colClasses = c("character", "character", "numeric", rep("character",7)))
class(gdpData$Gross.domestic.product.2012)
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"), colClasses = c("character", "numeric", rep("character",7)))
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"))
gdpData <- gdpData[!is.na(gdpData$X),]
gdpData <- gdpData[!is.na(gdpData$Gross.domestic.product.2012),]
View(gdpData)
View(gdpData)
View(gdpData)
gdpData$Gross.domestic.product.2012 <- as.numeric(gdpData$Gross.domestic.product.2012)
View(gdpData)
gdpData <- read.csv("gdp.csv", na.strings = c("", "NA"))
gdpData <- gdpData[!is.na(gdpData$X),]
gdpData <- gdpData[!is.na(gdpData$Gross.domestic.product.2012),]
View(gdpEdu)
View(gdpData)
gdpData$Gross.domestic.product.2012 <- as.numeric(as.character(gdpData$Gross.domestic.product.2012))
View(gdpData)
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
gdpEduArranged <- arrange(gdpEdu, Gross.domestic.product.2012)
View(gdpEduArranged)
gdpEduArranged <- arrange(gdpEdu, desc(Gross.domestic.product.2012))
View(gdpEduArranged)
gdpEdu$Income.Group <- character(gdpEdu$Income.Group)
gdpEdu$Income.Group <- as.character(gdpEdu$Income.Group)
highIncomeOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: OECD"),]
highIncomeOECD <- highIncomeOECD$Gross.domestic.product.2012
highIncomeOECD <- as.numeric(highIncomeOECD)
mean(highIncomeOECD)
highIncomeNonOECD <- gdpEdu[which(gdpEdu$Income.Group == "High income: nonOECD"),]
highIncomeNonOECD <- highIncomeNonOECD$Gross.domestic.product.2012
highIncomeNonOECD <- as.numeric(highIncomeNonOECD)
mean(highIncomeOECD)
mean(highIncomeNonOECD)
View(gdpData)
View(eduData)
library(Hmisc)
gdpEdu$Income.Quantile <- cut2(gdpEdu$Income.Group, g=5)
gdpEdu$Income.Group
class(gdpEdu$Income.Group)
gdpEdu <- merge(gdpData, eduData, by.x="X", by.y="CountryCode")
gdpEdu$Income.Quantile <- cut2(gdpEdu$Income.Group, g=5)
class(gdpEdu$Income.Group)
levels(gdpEdu$Income.Group)
gdpEdu$Income.Quantile <- cut(gdpEdu$Income.Group, breaks = 5)
?cut
gdpEdu$Income.Quantile <- cut(gdpEdu$Gross.domestic.product.2012, breaks = 5)
head(gdpEdu$Income.Quantile)
table(gdpEdu$Income.Quantile, gdpEdu$Income.Group)
setwd("~/Workspace/Coursera/Cleaning_Data/course_project")
activity_labels <- read.table("/data/activity_labels.txt")
activity_labels <- read.table("./data/activity_labels.txt")
View(activity_labels)
training_set <- read.table("./data/train/X_train.txt")
training_labels <- read.table("./data/train/y_train.txt")
test_set <- read.table("./data/test/X_test.txt")
test_labels <- read.table("./data/test/y_test.txt")
View(training_labels)
View(activity_labels)
View(test_set)
training_subject <- read.table("./data/train/subjet_test.txt")
training_subject <- read.table("./data/train/subject_test.txt")
training_subject <- read.table("./data/train/subject_train.txt")
training_subject <- read.table("./data/test/subject_test.txt")
features <- read.table("./data/features.txt")
training_subject <- read.table("./data/test/subject_test.txt")
training_subject <- read.table("./data/train/subject_train.txt")
testing_subject <- read.table("./data/test/subject_test.txt")
View(training_set)
View(training_set)
View(features)
View(features)
colname(test_set) <- features$V2
colnames(test_set) <- features$V2
View(test_set)
colnames(training_set) <- features$V2
?rbind
data_set <- rbind(test_set, training_set)
View(data_set)
View(features)
?grepl
mean_cols <- features$V2[grepl("^m.*\\mean", features$V2)]
mean_cols
View(features)
mean_cols <- features$V2[grepl("^m.*\\mean()", features$V2)]
mean_cols
View(features)
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
read.csv(path2csv, stringsAsFators = FALSE)
?read.csv
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mdf")
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(r_arch:country:cran)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2"| country == "IN")
filter(cran, country == "US"| country == "IN")
filter(cran, size > 100500 & r_os == "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, (size:ip_id))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10, correct_size = bytes + 1000)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10, correct_size = size + 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
?summarize
summarise(cran, avg_bytes = mean(size))
summarize(cran, avg_bytes = mean(size))
remove.packages(Hmisc)
remove.packages("Hmisc")
summarize(cran, avg_bytes = mean(size))
summarize(cran, avg_bytes = mean(size))
?summarize
summarize(cran, avg_bytes = mean(size))
dplyr::summarize(cran, avg_bytes = mean(size))
summarize(cran, avg_bytes = mean(size))
summarize_(cran, avg_bytes = mean(size))
library(dplyr)
packageVersion("dplyr")
summarize(cran, avg_bytes = mean(size))
dplyr::summarize(cran, avg_bytes = mean(size))
detach("package:Hmisc", unload=TRUE)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
mean_std_dataset <- tbl_df(data_set)
View(features)
mean_std_dataset <- select(mean_std_dataset, tBodyAcc-mean()-X:tBodyAcc-std()-Z, tGravityAcc-mean()-X:tGravityAcc-std()-Z)
mean_std_dataset <- select(mean_std_dataset,mean_std_dataset$tBodyAcc-mean()-X:tBodyAcc-std()-Z, tGravityAcc-mean()-X:tGravityAcc-std()-Z)
mean_std_dataset <- select(mean_std_dataset, "mean_std_dataset$tBodyAcc-mean()-X":tBodyAcc-std()-Z, tGravityAcc-mean()-X:tGravityAcc-std()-Z)
mean_std_dataset <- select(mean_std_dataset, "mean_std_dataset$tBodyAcc-mean()-X":"mean_std_dataset$meantBodyAcc-std()-Z", tGravityAcc-mean()-X:tGravityAcc-std()-Z)
mean_std_dataset <- select(mean_std_dataset, 1:3,4:6)
?grepl
mean_data_set <- data_set[ , grepl("-mean()", colnames(data_set))]
View(mean_data_set)
std_data_set <- data_set[ , grepl("-std()", colnames(data_set))]
mean_std_dataset <- cbind(mean_data_set, std_data_set)
View(mean_std_dataset)
View(features)
library(dplyr)
activity_labels <- read.table("./data/activity_labels.txt")
training_set <- read.table("./data/train/X_train.txt")
training_labels <- read.table("./data/train/y_train.txt")
training_subject <- read.table("./data/train/subject_train.txt")
test_set <- read.table("./data/test/X_test.txt")
test_labels <- read.table("./data/test/y_test.txt")
testing_subject <- read.table("./data/test/subject_test.txt")
features <- read.table("./data/features.txt")
colnames(test_set) <- features$V2
colnames(training_set) <- features$V2
#Full data set. Does it have duplicate column headers?
data_set <- rbind(test_set, training_set)
mean_data_set <- data_set[ , grepl("-mean()", colnames(data_set))]
std_data_set <- data_set[ , grepl("-std()", colnames(data_set))]
mean_std_dataset <- cbind(mean_data_set, std_data_set)
View(activity_labels)
View(activity_labels)
View(data_set)
View(training_set)
View(test_labels)
data_labels <- rbind(test_labels, training_labels)
mean_data_set <- cbind(data_labels, mean_std_dataset)
View(mean_std_dataset)
View(data_labels)
mean_std_dataset <- cbind(data_labels, mean_std_dataset)
View(mean_std_dataset)
View(data_labels)
View(activity_labels)
View(mean_std_dataset)
activities <- mean_std_dataset[,1]
for(i in 1:length(activities)){
print(activities[i])
}
View(activity_labels)
for(i in 1:length(activities)){
activity <- activity_labels[activity_labels$V1 == activities[i], 2]
print(activity)
}
activities <- as.character(activities)
for(i in 1:length(activities)){
activity <- activity_labels[activity_labels$V1 == activities[i], 2]
print(activity)
}
activities <- as.character(activities)
class(activity_labels$V2)
activity_labels$V2 <- as.character(activity_labels$V2)
for(i in 1:length(activities)){
activity <- activity_labels[activity_labels$V1 == activities[i], 2]
print(activity)
}
for(i in 1:length(activities)){
activity <- activity_labels[activity_labels$V1 == activities[i], 2]
activities[i] <- activity
}
pretty_mean_std_dataset <- cbind(activities, mean_std_dataset)
View(pretty_mean_std_dataset)
